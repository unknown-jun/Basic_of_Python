{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNl19SRxfWs8o1smCl7Uvev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unknown-jun/Basic_of_Python/blob/master/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwRAFBMDSkvs"
      },
      "source": [
        "서포트 벡터 머신은 기계학습 분야의 하나로 패턴 인식, 자료분석을 위한 지도학습 모델이며 주로 분류와 회귀분석을 위해 사용함.  \n",
        "서포트 벡터 머신 알고리즘은 데이터를 분류하는 가장 큰 폭을 가진 경계를 찾는 알고리즘.  \n",
        "비선형 분류를 하기 위해서 주어진 데이터를 고차원 특징 공간으로 사상하는 작업이 필요한데, 이를 효율적으로 하기 위해 커널 트릭을 사용하기도 한다.\n",
        "\n",
        "# 타이타닉을 이용한 SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNeb6gV3SlAr"
      },
      "source": [
        "### 기본 라이브러리 불러오기\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTg0q_zMUOpy"
      },
      "source": [
        "'''\n",
        "[Step 1] 데이터 준비/ 기본 설정\n",
        "'''\n",
        "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "#  IPython 디스플레이 설정 - 출력할 열의 개수 한도 늘리기\n",
        "pd.set_option('display.max_columns', 15)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGZcDQMaUP6V"
      },
      "source": [
        "'''\n",
        "[Step 2] 데이터 탐색/ 전처리\n",
        "'''\n",
        "\n",
        "# NaN값이 많은 deck 열을 삭제, embarked와 내용이 겹치는 embark_town 열을 삭제\n",
        "rdf = df.drop(['deck', 'embark_town'], axis=1)  \n",
        "\n",
        "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
        "rdf = rdf.dropna(subset=['age'], how='any', axis=0)  \n",
        "\n",
        "# embarked 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
        "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()   \n",
        "rdf['embarked'].fillna(most_freq, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "8KZkGSkJUQ2m",
        "outputId": "21e759b4-b901-4e7f-f34f-7a65da339419"
      },
      "source": [
        "'''\n",
        "[Step 3] 분석에 사용할 속성을 선택\n",
        "'''\n",
        "\n",
        "# 분석에 활용할 열(속성)을 선택 \n",
        "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked']]\n",
        "ndf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>885</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>887</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>889</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>714 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     survived  pclass     sex   age  sibsp  parch embarked\n",
              "0           0       3    male  22.0      1      0        S\n",
              "1           1       1  female  38.0      1      0        C\n",
              "2           1       3  female  26.0      0      0        S\n",
              "3           1       1  female  35.0      1      0        S\n",
              "4           0       3    male  35.0      0      0        S\n",
              "..        ...     ...     ...   ...    ...    ...      ...\n",
              "885         0       3  female  39.0      0      5        Q\n",
              "886         0       2    male  27.0      0      0        S\n",
              "887         1       1  female  19.0      0      0        S\n",
              "889         1       1    male  26.0      0      0        C\n",
              "890         0       3    male  32.0      0      0        Q\n",
              "\n",
              "[714 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcSs_VfPUavV"
      },
      "source": [
        "\n",
        "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
        "onehot_sex = pd.get_dummies(ndf['sex'])\n",
        "ndf = pd.concat([ndf, onehot_sex], axis=1)\n",
        "\n",
        "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
        "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
        "\n",
        "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1BfxiwrUSGf"
      },
      "source": [
        "'''\n",
        "[Step 4] 데이터셋 구분 - 훈련용(train data)/ 검증용(test data)\n",
        "'''\n",
        "\n",
        "# 속성(변수) 선택\n",
        "X=ndf[['pclass', 'age', 'sibsp', 'parch', 'female', 'male', \n",
        "       'town_C', 'town_Q', 'town_S']]  #독립 변수 X\n",
        "y=ndf['survived']                      #종속 변수 Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJqhni1pUvT0",
        "outputId": "4eef12a3-9675-4727-d6d1-5ec22e21951c"
      },
      "source": [
        "# 설명 변수 데이터를 정규화(normalization)\n",
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "\n",
        "# train data 와 test data로 구분(7:3 비율)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
        "\n",
        "print('train data 개수: ', X_train.shape)\n",
        "print('test data 개수: ', X_test.shape)\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data 개수:  (499, 9)\n",
            "test data 개수:  (215, 9)\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuKrDzIFUTXP",
        "outputId": "25d03239-bbe7-4a50-8ce6-40c7fdbe1588"
      },
      "source": [
        "'''\n",
        "[Step 5] SVM 분류 모형 - sklearn 사용\n",
        "'''\n",
        "\n",
        "# sklearn 라이브러리에서 SVM 분류 모형 가져오기\n",
        "from sklearn import svm\n",
        "\n",
        "# 모형 객체 생성 (kernel='rbf' 적용)\n",
        "svm_model = svm.SVC(kernel='rbf')\n",
        "svm_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-_n5gdLU8Dr",
        "outputId": "447f8660-c8e5-49a7-dde3-a55598dda6af"
      },
      "source": [
        "# train data를 가지고 모형 학습\n",
        "svm_model.fit(X_train, y_train)   \n",
        "\n",
        "# test data를 가지고 y_hat을 예측 (분류) \n",
        "y_hat = svm_model.predict(X_test)\n",
        "\n",
        "print(y_hat[0:10])\n",
        "print(y_test.values[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 0 1 0 0 0]\n",
            "[0 0 1 0 0 1 1 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8LPbm6-VDhX",
        "outputId": "62c61c59-2ca9-4d1c-b696-63edc0a11765"
      },
      "source": [
        "# 모형 성능 평가 - Confusion Matrix 계산\n",
        "from sklearn import metrics \n",
        "svm_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
        "print(svm_matrix)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "# 모형 성능 평가 - 평가지표 계산\n",
        "svm_report = metrics.classification_report(y_test, y_hat)            \n",
        "print(svm_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[120   5]\n",
            " [ 35  55]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.96      0.86       125\n",
            "           1       0.92      0.61      0.73        90\n",
            "\n",
            "    accuracy                           0.81       215\n",
            "   macro avg       0.85      0.79      0.80       215\n",
            "weighted avg       0.83      0.81      0.81       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUWJ570GVrcF"
      },
      "source": [
        "문제. 지금까지의 정확도는 0.81인데 아이와 여자 먼저라는 파생변수를 추가하면 정확도가 더 올라가는지 확인하시오"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDGhr2ijVrQj",
        "outputId": "bfb391cf-b92a-402e-b591-c22df99acdb4"
      },
      "source": [
        "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# NaN값이 많은 deck 열을 삭제, embarked와 내용이 겹치는 embark_town 열을 삭제\n",
        "rdf = df.drop(['deck', 'embark_town'], axis=1)  \n",
        "\n",
        "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
        "rdf = rdf.dropna(subset=['age'], how='any', axis=0)  \n",
        "\n",
        "# embarked 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
        "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()   \n",
        "rdf['embarked'].fillna(most_freq, inplace=True)\n",
        "\n",
        "# 파생변수 생성\n",
        "mask = ( rdf.age < 10 ) | ( rdf.sex=='female')\n",
        "mask.astype(int) # True 를 1 로 변경하고 False 를 0 으로 변경\n",
        "rdf['women_child'] = mask.astype(int)\n",
        "\n",
        "# 가정2: fare가 0인 인원은 선원일 것이며 대다수의 남자 선원은 죽었을 것이다.\n",
        "mask = ( rdf.fare == 0 ) & ( rdf.sex== 'male' )\n",
        "rdf['male_fare0'] = mask.astype(int)\n",
        "\n",
        "# 가정3: 3등실 남자 인원은 모두 죽었을 것이다.\n",
        "mask = ( rdf.pclass != 3 ) & ( rdf.sex== 'male' )\n",
        "rdf['male_Third'] = mask.astype(int)\n",
        "\n",
        "# 가정4: 50살 이상의 남자는 대다수가 죽었을 것이다.\n",
        "mask = ( rdf.age < 50 ) & ( rdf.sex== 'male' )\n",
        "rdf['male_age50'] = mask.astype(int)\n",
        "\n",
        "# 분석에 활용할 열(속성)을 선택 \n",
        "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked','women_child','male_fare0','male_Third','male_age50']]\n",
        "\n",
        "\n",
        "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
        "onehot_sex = pd.get_dummies(ndf['sex'])\n",
        "ndf = pd.concat([ndf, onehot_sex], axis=1)\n",
        "\n",
        "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
        "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
        "\n",
        "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# 속성(변수) 선택\n",
        "X=ndf[['pclass', 'age', 'sibsp', 'parch',\n",
        "       'women_child','male_fare0','male_Third','male_age50']]  #독립 변수 X\n",
        "y=ndf['survived']                      #종속 변수 Y\n",
        "\n",
        "# 설명 변수 데이터를 정규화(normalization)\n",
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "\n",
        "# train data 와 test data로 구분(7:3 비율)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10) \n",
        "\n",
        "# sklearn 라이브러리에서 SVM 분류 모형 가져오기\n",
        "from sklearn import svm\n",
        "\n",
        "# 모형 객체 생성 (kernel='rbf' 적용)\n",
        "svm_model = svm.SVC(kernel='rbf')\n",
        "\n",
        "# train data를 가지고 모형 학습\n",
        "svm_model.fit(X_train, y_train)   \n",
        "\n",
        "# test data를 가지고 y_hat을 예측 (분류) \n",
        "y_hat = svm_model.predict(X_test)\n",
        "\n",
        "# 모형 성능 평가 - Confusion Matrix 계산\n",
        "from sklearn import metrics \n",
        "svm_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
        "print(svm_matrix)\n",
        "print('\\n')\n",
        "\n",
        "# 모형 성능 평가 - 평가지표 계산\n",
        "svm_report = metrics.classification_report(y_test, y_hat)            \n",
        "print(svm_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[119   6]\n",
            " [ 29  61]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.95      0.87       125\n",
            "           1       0.91      0.68      0.78        90\n",
            "\n",
            "    accuracy                           0.84       215\n",
            "   macro avg       0.86      0.81      0.82       215\n",
            "weighted avg       0.85      0.84      0.83       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jnpqNmwX3Qh"
      },
      "source": [
        "문제. grid search 를 이용해서 최적의 하이퍼 파라미터의 조합을 알아내시오"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I87IeWS3Ripv",
        "outputId": "dce85b49-bbab-426b-b760-9a028664934e"
      },
      "source": [
        "# load_dataset 함수를 사용하여 데이터프레임으로 변환\n",
        "df = sns.load_dataset('titanic')\n",
        "\n",
        "# NaN값이 많은 deck 열을 삭제, embarked와 내용이 겹치는 embark_town 열을 삭제\n",
        "rdf = df.drop(['deck', 'embark_town'], axis=1)  \n",
        "\n",
        "# age 열에 나이 데이터가 없는 모든 행을 삭제 - age 열(891개 중 177개의 NaN 값)\n",
        "rdf = rdf.dropna(subset=['age'], how='any', axis=0)  \n",
        "\n",
        "# embarked 열의 NaN값을 승선도시 중에서 가장 많이 출현한 값으로 치환하기\n",
        "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax()   \n",
        "rdf['embarked'].fillna(most_freq, inplace=True)\n",
        "\n",
        "# 파생변수 생성\n",
        "mask = ( rdf.age < 10 ) | ( rdf.sex=='female')\n",
        "mask.astype(int) # True 를 1 로 변경하고 False 를 0 으로 변경\n",
        "rdf['women_child'] = mask.astype(int)\n",
        "\n",
        "# 가정2: fare가 0인 인원은 선원일 것이며 대다수의 남자 선원은 죽었을 것이다.\n",
        "mask = ( rdf.fare == 0 ) \n",
        "rdf['male_fare0'] = mask.astype(int)\n",
        "\n",
        "# 가정3: 3등실 남자 인원은 모두 죽었을 것이다.\n",
        "mask = ( rdf.pclass != 3 )\n",
        "rdf['male_Third'] = mask.astype(int)\n",
        "\n",
        "# 가정4: 50살 이상의 남자는 대다수가 죽었을 것이다.\n",
        "mask = ( rdf.age < 50 ) \n",
        "rdf['male_age50'] = mask.astype(int)\n",
        "\n",
        "# 분석에 활용할 열(속성)을 선택 \n",
        "ndf = rdf[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'embarked','women_child','male_fare0','male_Third','male_age50']]\n",
        "\n",
        "\n",
        "# 원핫인코딩 - 범주형 데이터를 모형이 인식할 수 있도록 숫자형으로 변환\n",
        "onehot_sex = pd.get_dummies(ndf['sex'])\n",
        "ndf = pd.concat([ndf, onehot_sex], axis=1)\n",
        "\n",
        "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
        "ndf = pd.concat([ndf, onehot_embarked], axis=1)\n",
        "\n",
        "ndf.drop(['sex', 'embarked'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# 속성(변수) 선택\n",
        "X=ndf[['pclass', 'age', 'sibsp', 'parch',\n",
        "       'women_child','male_fare0','male_Third','male_age50']]  #독립 변수 X\n",
        "y=ndf['survived']                      #종속 변수 Y\n",
        "\n",
        "# 설명 변수 데이터를 정규화(normalization)\n",
        "from sklearn import preprocessing\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "\n",
        "# train data 와 test data로 구분(7:3 비율)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
        "\n",
        "# sklearn 라이브러리에서 SVM 분류 모형 가져오기\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "  \n",
        "# defining parameter range \n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
        "              'kernel': ['rbf','poly', 'sigmoid','linear']}  \n",
        "  \n",
        "grid = GridSearchCV( svm.SVC(), param_grid, refit = True,cv=3, n_jobs = -1, verbose = 2 )\n",
        "\n",
        "\"\"\"\n",
        "estimator : classifier, regressor, pipeline이 사용될 수 있다.\n",
        "\n",
        "param_grid : 파라미터 딕셔너리. (파라미터명과 사용될 여러 파라미터 값을 지정)\n",
        "\n",
        "scoring : 예측 성능을 측정할 평가 방법. 보통은 사이킷런에서 제공하는 문자열 \n",
        "        (예: ‘accuracy’)을 넣지만 별도의 함수도 직접 지정이 가능하다.\n",
        "\n",
        "cv : 교차 검증을 위해 분할되는 폴드 수.\n",
        "\n",
        "refit : True면 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 \n",
        "        estimator 객체를 해당 하이퍼 파라미터로 재학습시킨다. (default:True)\n",
        "\"\"\"\n",
        "\n",
        "# fitting the model for grid search \n",
        "grid.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:   49.3s\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
              "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
              "                         'kernel': ['rbf', 'poly', 'sigmoid', 'linear']},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m5xDLdwY6sK",
        "outputId": "e53bf3da-0a99-40ef-92d0-e7d7f4e264d8"
      },
      "source": [
        "# test data를 가지고 y_hat을 예측 (분류) \n",
        "y_hat = grid.predict(X_test)\n",
        "\n",
        "print(y_hat[0:10])\n",
        "print(y_test.values[0:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 1 0 0 1 1 0 0 0]\n",
            "[0 0 1 0 0 1 1 1 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGKh90_tXrjR",
        "outputId": "69ca7468-3aed-41b4-ad19-c215b2dadfb8"
      },
      "source": [
        "# 모형 성능 평가 - Confusion Matrix 계산\n",
        "from sklearn import metrics \n",
        "svm_matrix = metrics.confusion_matrix(y_test, y_hat)  \n",
        "print(svm_matrix)\n",
        "print('\\n')\n",
        "\n",
        "# 모형 성능 평가 - 평가지표 계산\n",
        "svm_report = metrics.classification_report(y_test, y_hat)            \n",
        "print(svm_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[108  17]\n",
            " [ 29  61]]\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.86      0.82       125\n",
            "           1       0.78      0.68      0.73        90\n",
            "\n",
            "    accuracy                           0.79       215\n",
            "   macro avg       0.79      0.77      0.78       215\n",
            "weighted avg       0.79      0.79      0.78       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}